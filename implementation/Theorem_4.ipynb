{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This document contains 3 implementations of computing the 0-dimensional PH of the product of 2 vertex-based filtrations:\n",
        "\n",
        "1. Computing PH of the product directly using an union-find method.\n",
        "2. Theorem 4 of our paper.\n",
        "3. Computing PH of the product directly using the gudhi library.\n",
        "\n",
        "We then compute them on pairs of graphs loaded with the BREC dataset.\n",
        "\n",
        "NOTE: For convenience, we modeled time t = +infinity as -1 in the code file here, and the filtration values are assumed to be positive in the algorithm. We also precomputed the values at time t = -infinity appropriately."
      ],
      "metadata": {
        "id": "YKIr014OaJ6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gotsouXmfAOz"
      },
      "outputs": [],
      "source": [
        "# Uncomment to install the gudhi package\n",
        "# !pip install gudhi\n",
        "import torch\n",
        "import itertools\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import random\n",
        "import gudhi\n",
        "import math\n",
        "from itertools import product\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2mMad0fxszN"
      },
      "outputs": [],
      "source": [
        "# The code implementation of the Union Find PH Based Method\n",
        "# The code is adapted from codes produced in the paper:\n",
        "# \"Going beyond persistent homology using persistent homology\"\n",
        "# by Johanna Immonen, Amauri H. Souza, and Vikas Garg.\n",
        "\n",
        "class UnionFind():\n",
        "    def __init__(self,N):\n",
        "        self._parents = list(range(0, N))\n",
        "\n",
        "    def find(self, p):\n",
        "        return(self._parents[p])\n",
        "\n",
        "    def merge(self, p, q):\n",
        "        root_p, root_q = self._parents[p], self._parents[q]\n",
        "        for i in range(0, len(self._parents)):\n",
        "            if(self._parents[i] == root_p):\n",
        "                self._parents[i] = root_q\n",
        "\n",
        "    def connected(self,p,q):\n",
        "        return self._parents[p] == self._parents[q]\n",
        "\n",
        "    def roots(self):\n",
        "        roots = []\n",
        "        for i in range(0, len(self._parents)):\n",
        "            if self._parents[i] == i:\n",
        "                roots.append(i)\n",
        "        return roots\n",
        "\n",
        "\n",
        "def persistence_routine(filtered_v, filtered_e, edge_indices):\n",
        "\n",
        "    n, m = filtered_v.shape[0], edge_indices.shape[1]\n",
        "\n",
        "    filtered_e, sorted_indices = torch.sort(filtered_e)\n",
        "    uf = UnionFind(n)\n",
        "    persistence = torch.zeros((n, 3), device=filtered_v.device)\n",
        "    persistence1 = torch.zeros((m, 2), device=filtered_v.device)\n",
        "\n",
        "    unpaired_value = filtered_e[-1]  # used as infinity\n",
        "\n",
        "    for edge_index, edge_weight in zip(sorted_indices, filtered_e):\n",
        "\n",
        "        nodes = edge_indices[:, edge_index]\n",
        "        younger = uf.find(nodes[0])\n",
        "        older = uf.find(nodes[1])\n",
        "        if younger == older:\n",
        "            persistence1[edge_index, 0] = edge_weight # filtered_e[edge_index]\n",
        "            persistence1[edge_index, 1] = -1\n",
        "            continue\n",
        "        else:\n",
        "            if filtered_v[younger] < filtered_v[older]:\n",
        "                younger, older = older, younger\n",
        "                nodes = torch.flip(nodes, [0])\n",
        "\n",
        "        persistence[younger, 0] = younger\n",
        "        persistence[younger, 1] = filtered_v[younger]\n",
        "        persistence[younger, 2] = edge_weight\n",
        "\n",
        "        uf.merge(nodes[0], nodes[1])\n",
        "\n",
        "    for root in uf.roots():\n",
        "        persistence[root, 0] = root\n",
        "        persistence[root, 1] = filtered_v[root]\n",
        "        persistence[root, 2] = -1\n",
        "\n",
        "    return persistence, persistence1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U95YTwbcfwXJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HffwcyUVwYSo"
      },
      "outputs": [],
      "source": [
        "# Utility function to print the output of the persistence diagram in readable way\n",
        "def pretty_print(pd_with_labels):\n",
        "  for elt in pd_with_labels:\n",
        "    for i, j, birth, death in elt:\n",
        "      if birth == 2.0:\n",
        "        print(\"Label: \" + str((i, j)) + \" B/D: \" + str((birth, death)))\n",
        "\n",
        "# Implementation of Theorem 4 of our paper.\n",
        "# Input: Takes in a graph data item of the form of a tuple\n",
        "# (graph_data_item 0, graph_data_item 1)\n",
        "\n",
        "# For i = 0 or 1, graph_data_item i is composed of 4 items for a graph G of n + 1 vertices with a vertex filtration function fv\n",
        "# The vertex set of the graph is given by {0, 1, ..., n}.\n",
        "# The 4 items in graph_data_item are:\n",
        "\n",
        "# input_v - a list of numbers that specifies the value of fv on the index i (this is not used in the algorithm)\n",
        "# edge_index - list of edges of the graph, being tuples of the form (i,j) for vertices i and j (made in pytorch)\n",
        "# filtered_v - torch.Tensor(input_v)\n",
        "# filtered_e - The value of fv on edges, this can be made by the line:\n",
        "# filtered_e, _ = torch.max(torch.stack((filtered_v[edge_index[0]], filtered_v[edge_index[1]])), axis=0)\n",
        "\n",
        "def thm4_ph(graph_data_item):\n",
        "  _, edge_index_G, filtered_v_G, filtered_e_G = graph_data_item[0]\n",
        "  _, edge_index_H, filtered_v_H, filtered_e_H = graph_data_item[1]\n",
        "\n",
        "  # Precompute the Persistence Pairs using the Union Find Code Above\n",
        "  impl1 = persistence_routine(filtered_v_G, filtered_e_G, edge_index_G)[0]\n",
        "  impl2 = persistence_routine(filtered_v_H, filtered_e_H, edge_index_H)[0]\n",
        "\n",
        "  # Both should have the same filtration steps, this uniformizes their time steps\n",
        "  filtration_steps = torch.unique(torch.cat((filtered_v_G, filtered_v_H))).tolist()\n",
        "  filtration_steps.sort()\n",
        "  filtration_steps.append(-1)\n",
        "\n",
        "  # Initialize non-trivial deaths list\n",
        "  G_nd = torch.zeros(len(filtration_steps)+1).tolist()\n",
        "  H_nd = torch.zeros(len(filtration_steps)+1).tolist()\n",
        "  G_nd[0] = (0, [])\n",
        "  H_nd[0] = (0, [])\n",
        "\n",
        "  # Initialize the trivial deaths list\n",
        "  G_td = torch.zeros(len(filtration_steps)+1).tolist()\n",
        "  H_td = torch.zeros(len(filtration_steps)+1).tolist()\n",
        "  G_td[0] = (0, [])\n",
        "  H_td[0] = (0, [])\n",
        "\n",
        "  # Initialize the non-trivial births list\n",
        "  G_nb = torch.zeros(len(filtration_steps)+1).tolist()\n",
        "  H_nb = torch.zeros(len(filtration_steps)+1).tolist()\n",
        "  G_nb[0] = (0, [])\n",
        "  H_nb[0] = (0, [])\n",
        "\n",
        "  # Precompute the non-trivial deaths, trivial deaths, and the non-trivial births\n",
        "  for i in range(0, len(filtration_steps)):\n",
        "    a_i = filtration_steps[i]\n",
        "\n",
        "    G_deaths = [int(x[0].item()) for x in impl1 if x[2] == a_i and x[1] != x[2]]\n",
        "    H_deaths = [int(x[0].item()) for x in impl2 if x[2] == a_i and x[1] != x[2]]\n",
        "    G_nd[i+1] = (len(G_deaths), G_deaths)\n",
        "    H_nd[i+1] = (len(H_deaths), H_deaths)\n",
        "\n",
        "    G_trivial_deaths = [int(x[0].item()) for x in impl1 if x[2] == a_i and x[1] == x[2]]\n",
        "    H_trivial_deaths = [int(x[0].item()) for x in impl2 if x[2] == a_i and x[1] == x[2]]\n",
        "    G_td[i+1] = (len(G_trivial_deaths), G_trivial_deaths)\n",
        "    H_td[i+1] = (len(H_trivial_deaths), H_trivial_deaths)\n",
        "\n",
        "\n",
        "    G_births = [int(x[0].item()) for x in impl1 if x[1] == a_i and x[1] != x[2]]\n",
        "    H_births = [int(x[0].item()) for x in impl2 if x[1] == a_i and x[1] != x[2]]\n",
        "\n",
        "    G_nb[i+1] = (len(G_births), G_births)\n",
        "    H_nb[i+1] = (len(H_births), H_births)\n",
        "\n",
        "  # Makes a count of the zeroth Betti number list\n",
        "  G_b0 = torch.zeros(len(filtration_steps)+1).tolist()\n",
        "  H_b0 = torch.zeros(len(filtration_steps)+1).tolist()\n",
        "  G_b0[0] = (0, [])\n",
        "  H_b0[0] = (0, [])\n",
        "\n",
        "  for i in range(0, len(filtration_steps)):\n",
        "    G_count = G_b0[i][0] + G_nb[i+1][0] - G_nd[i+1][0]\n",
        "    H_count = H_b0[i][0] + H_nb[i+1][0] - H_nd[i+1][0]\n",
        "\n",
        "    G_list = list(set(G_b0[i][1] + G_nb[i+1][1]).difference(set(G_nd[i+1][1])))\n",
        "    H_list = list(set(H_b0[i][1] + H_nb[i+1][1]).difference(set(H_nd[i+1][1])))\n",
        "\n",
        "    G_b0[i+1] = (G_count, G_list)\n",
        "    H_b0[i+1] = (H_count, H_list)\n",
        "\n",
        "  # Now we start computing 0-dim PH of the Product\n",
        "  nG = filtered_v_G.shape[0]\n",
        "  nH = filtered_v_H.shape[0]\n",
        "\n",
        "  # Initialize Persistence\n",
        "  persistence = []\n",
        "  for i in range(0, nG):\n",
        "    input = []\n",
        "    for j in range(0, nH):\n",
        "      input.append([i, j, torch.max(filtered_v_G[i], filtered_v_H[j]).item(), None])\n",
        "    persistence.append(input)\n",
        "\n",
        "  # Create the non-trivial non-permanent holes\n",
        "  for i in range(0, len(filtration_steps)):\n",
        "    a_i = filtration_steps[i]\n",
        "    g_count, g_deaths = G_nd[i+1]\n",
        "    h_count, h_deaths = H_nd[i+1]\n",
        "\n",
        "    _, g_t_deaths = G_td[i+1]\n",
        "    _, h_t_deaths = H_td[i+1]\n",
        "\n",
        "    _, g_births = G_nb[i+1]\n",
        "    _, h_births = H_nb[i+1]\n",
        "\n",
        "    _, g_betti0 = G_b0[i+1]\n",
        "    _, h_betti0 = H_b0[i+1]\n",
        "\n",
        "    # Mark Non-trivial Deaths\n",
        "    for v in h_deaths:\n",
        "      for ell in range(0, len(filtered_v_G)):\n",
        "        item = persistence[ell][v]\n",
        "        if item[3] == None and (item[2] < a_i or a_i == -1): # ie. the tuple has not been marked dead yet\n",
        "          item[3] = a_i\n",
        "    for w in g_deaths:\n",
        "      for k in range(0, len(filtered_v_H)):\n",
        "        item = persistence[w][k]\n",
        "        if item[3] == None and (item[2] < a_i or a_i == -1): # ie. the tuple has not been marked dead yet\n",
        "          item[3] = a_i\n",
        "\n",
        "    _, h_betti_prev = H_b0[i]\n",
        "    _, g_betti_prev = G_b0[i]\n",
        "\n",
        "    non_trivial_births_current = list(product(g_births, h_betti_prev)) + list(product(g_betti0, h_births))\n",
        "    non_trivial_deaths_second = list(product(g_births, h_deaths))\n",
        "    # Using the following list also gives the same output\n",
        "    # non_trivial_deaths_second = list(product(g_betti0, h_deaths))\n",
        "    non_trivial_births_current = list(set(non_trivial_births_current).difference(set(non_trivial_deaths_second)))\n",
        "\n",
        "    # There is an alternative way to compute the non_trivial_births_current as follows:\n",
        "    # non_trivial_births_current = list(product(g_births, h_betti_prev)) + list(product(g_betti0, h_births))\n",
        "    # non_trivial_births_current_alt = list(product(g_betti_prev, h_births)) + list(product(g_births, h_betti0))\n",
        "    # non_trivial_births_current = list(set(non_trivial_births_current).intersection(set(non_trivial_births_current_alt)))\n",
        "\n",
        "    # Mark Trivial Deaths\n",
        "    for a in range(0, len(filtered_v_G)):\n",
        "      for b in range(0, len(filtered_v_H)):\n",
        "        item = persistence[a][b]\n",
        "        if item[3] == None and item[2] == a_i and (a, b) not in non_trivial_births_current:\n",
        "          item[3] = a_i\n",
        "\n",
        "  # Forget about the labels to the persistence pairs at the end\n",
        "  projected_persistence = list(itertools.chain(*[[[float(x[2]), float(x[3])] for x in y] for y in persistence]))\n",
        "  return projected_persistence\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6t_ojIkI0fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1vORkrWQrmb"
      },
      "outputs": [],
      "source": [
        "# Utility Function - prints the output of persistent diagrams for gudhi and naive on G \\Box H. nH is the number of vertices in H.\n",
        "def pretty_print_prod(prod_pd_with_labels, nH):\n",
        "  for elt in prod_pd_with_labels:\n",
        "    i, birth, death = elt\n",
        "    y = i % nH\n",
        "    x = (i-y)/nH\n",
        "    print(\"Label: \" + str((x,y)) + \", B/D: \" + str((birth, death)))\n",
        "\n",
        "\n",
        "# Given a pair (i, j), thought of as a node in the product G \\Box H, and nH, the number of vertices in H\n",
        "# Returns the index (i, j) has if the matrix of vertices is flattened into a single list.\n",
        "def prod(pair, nH):\n",
        "  x = pair[0]\n",
        "  y = pair[1]\n",
        "  return nH*x + y\n",
        "\n",
        "# Naive implementation by computing PH of the whole product using the union-find structure\n",
        "# The inputs are - graph_data_item (explained in the implementation for Theorem 4)\n",
        "# P - the networkx graph of the product of the graph G and the graph H\n",
        "def naive_pd(graph_data_item, P):\n",
        "  input_v_G, edge_index_G, filtered_v_G, filtered_e_G = graph_data_item[0]\n",
        "  input_v_H, edge_index_H, filtered_v_H, filtered_e_H = graph_data_item[1]\n",
        "\n",
        "  prod_vert_index = []\n",
        "  prod_vert_value = []\n",
        "  prod_edge_index = [[], []]\n",
        "\n",
        "  base_edge_index_G = np.transpose(edge_index_G.numpy()).tolist()\n",
        "  base_edge_index_H = np.transpose(edge_index_H.numpy()).tolist()\n",
        "  for item in base_edge_index_G:\n",
        "    item.sort()\n",
        "  for item in base_edge_index_H:\n",
        "    item.sort()\n",
        "\n",
        "  # print(base_edge_index_G)\n",
        "  # print(base_edge_index_H)\n",
        "  # print(\"-----------------\")\n",
        "\n",
        "  nG = filtered_v_G.shape[0]\n",
        "  nH = filtered_v_H.shape[0]\n",
        "\n",
        "  for i in range(0, nG):\n",
        "    for j in range(0, nH):\n",
        "      prod_vert_index.append((i,j))\n",
        "      prod_vert_value.append(max(input_v_G[i], input_v_H[j]))\n",
        "  # print(len(prod_vert_index))\n",
        "\n",
        "  for v,w in P.edges:\n",
        "    prod_edge_index[0].append(prod(v, nH))\n",
        "    prod_edge_index[1].append(prod(w, nH))\n",
        "\n",
        "\n",
        "  prod_edge_index_torch = torch.Tensor(prod_edge_index).long()\n",
        "  prod_filtered_v = torch.Tensor(prod_vert_value)\n",
        "  prod_filtered_e, _ = torch.max(torch.stack((prod_filtered_v[prod_edge_index_torch[0]], prod_filtered_v[prod_edge_index_torch[1]])), axis=0)\n",
        "\n",
        "  # print(prod_filtered_e)\n",
        "\n",
        "  # Computes the PH on the entire product using the union-find code\n",
        "  prod_ph = persistence_routine(prod_filtered_v, prod_filtered_e, prod_edge_index_torch)[0]\n",
        "  projected_prod_ph = [[x for x in y] for y in prod_ph[:, 1:].tolist()]\n",
        "\n",
        "  return projected_prod_ph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Fgb1vVYMzq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZqVNfJOEEKW"
      },
      "outputs": [],
      "source": [
        "# Naive implementation by computing PH of the whole product using the gudhi library\n",
        "# The inputs are - graph_data_item (explained in the implementation for Theorem 4)\n",
        "# P - the networkx graph of the product of the graph G and the graph H\n",
        "def gudhi_prod(graph_data_item, P):\n",
        "  input_v_G, edge_index_G, filtered_v_G, filtered_e_G = graph_data_item[0]\n",
        "  input_v_H, edge_index_H, filtered_v_H, filtered_e_H = graph_data_item[1]\n",
        "\n",
        "  st = gudhi.SimplexTree()\n",
        "\n",
        "  nG = filtered_v_G.shape[0]\n",
        "  nH = filtered_v_H.shape[0]\n",
        "\n",
        "  prod_vert_index = []\n",
        "  for i in range(0, nG):\n",
        "    for j in range(0, nH):\n",
        "      val_i = torch.max(filtered_v_G[i], filtered_v_H[j]).item()\n",
        "      st.insert([prod((i,j), nH)], filtration=val_i)\n",
        "      prod_vert_index.append((i,j))\n",
        "\n",
        "  base_edge_index_G = np.transpose(edge_index_G.numpy()).tolist()\n",
        "  base_edge_index_H = np.transpose(edge_index_H.numpy()).tolist()\n",
        "  for item in base_edge_index_G:\n",
        "    item.sort()\n",
        "  for item in base_edge_index_H:\n",
        "    item.sort()\n",
        "\n",
        "  for v,w in P.edges:\n",
        "      # print((v,w))\n",
        "      val_v = torch.max(filtered_v_G[v[0]], filtered_v_H[v[1]]).item()\n",
        "      val_w = torch.max(filtered_v_G[w[0]], filtered_v_H[w[1]]).item()\n",
        "      st.insert([prod(v, nH), prod(w, nH)], filtration=max(val_v, val_w))\n",
        "\n",
        "  st.make_filtration_non_decreasing()\n",
        "  dgms = st.persistence(min_persistence=-1)\n",
        "\n",
        "  dgms_no_dim = [list(x[1]) for x in dgms]\n",
        "  for item in dgms_no_dim:\n",
        "    _, d = item\n",
        "    if d == np.inf:\n",
        "      item[1] = -1.0\n",
        "  return dgms_no_dim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rest of the Code does a comparison testing between the 3 implementations to see that they agree with each other. We take the BREC dataset (see the paper for specifications) and compute the 0-th dim PH of the product of pair of graphs in the BREC dataset, using a degree-based filtration on the two components."
      ],
      "metadata": {
        "id": "ZXchENHLk5D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def get_dataset(name):\n",
        "    dataset = []\n",
        "    if name in ['basic', 'str', 'dr', '4vtx']:\n",
        "        # When you are running this, replace the following line with a link to the relevant file in the BREC dataset.\n",
        "        data = np.load(f'/content/drive/My Drive/Colab Notebooks/datasets/BREC/{name}.npy')\n",
        "        for i in range(0, data.size, 2):\n",
        "            if name == 'dr':\n",
        "                pyg_graph_1 =  nx.from_graph6_bytes(data[i])\n",
        "                pyg_graph_2 =  nx.from_graph6_bytes(data[i+1])\n",
        "            else:\n",
        "                pyg_graph_1 =  nx.from_graph6_bytes(data[i].encode())\n",
        "                pyg_graph_2 =  nx.from_graph6_bytes(data[i+1].encode())\n",
        "            dataset.append((pyg_graph_1, pyg_graph_2))\n",
        "        return dataset\n",
        "    elif name in ['regular', 'extension', 'cfi']:\n",
        "        # When you are running this, replace the following line with a link to the relevant file in the BREC dataset.\n",
        "        data = np.load(f'/content/drive/My Drive/Colab Notebooks/datasets/BREC/{name}.npy')\n",
        "        for i in range(0, data.size // 2):\n",
        "            g6_tuple = data[i]\n",
        "            if name == 'regular' or name == 'cfi':\n",
        "                pyg_graph_1 = nx.from_graph6_bytes(g6_tuple[0])\n",
        "                pyg_graph_2 = nx.from_graph6_bytes(g6_tuple[1])\n",
        "            else:\n",
        "                pyg_graph_1 = nx.from_graph6_bytes(g6_tuple[0].encode())\n",
        "                pyg_graph_2 = nx.from_graph6_bytes(g6_tuple[1].encode())\n",
        "            dataset.append((pyg_graph_1, pyg_graph_2))\n",
        "        return dataset\n",
        "\n",
        "dataset = get_dataset('basic')\n",
        "print(len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoD_zNJKk4Gv",
        "outputId": "fb1a670e-a617-4a0d-b377-11006e830fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the dataset inputs to entries for the 3 algorithms\n",
        "# Here we filtrate the two graphs using a degree-based vertex filtration.\n",
        "def dataset_entry_to_input(item):\n",
        "  G, H = item\n",
        "  G_edge_list = [[], []]\n",
        "  H_edge_list = [[], []]\n",
        "  for v0, v1 in G.edges:\n",
        "    G_edge_list[0].append(v0)\n",
        "    G_edge_list[1].append(v1)\n",
        "\n",
        "  for v0, v1 in H.edges:\n",
        "    H_edge_list[0].append(v0)\n",
        "    H_edge_list[1].append(v1)\n",
        "\n",
        "  G_nodes = list(G.nodes)\n",
        "  H_nodes = list(H.nodes)\n",
        "\n",
        "  # Degree\n",
        "  input_v_G = [G.degree[x] for x in G_nodes]\n",
        "  input_v_H = [H.degree[x] for x in H_nodes]\n",
        "\n",
        "  edge_index_G = torch.Tensor(G_edge_list).long()\n",
        "  filtered_v_G = torch.Tensor(input_v_G)\n",
        "  filtered_e_G, _ = torch.max(torch.stack((filtered_v_G[edge_index_G[0]], filtered_v_G[edge_index_G[1]])), axis=0)\n",
        "\n",
        "  edge_index_H = torch.Tensor(H_edge_list).long()\n",
        "  filtered_v_H = torch.Tensor(input_v_H)\n",
        "  filtered_e_H, _ = torch.max(torch.stack((filtered_v_H[edge_index_H[0]], filtered_v_H[edge_index_H[1]])), axis=0)\n",
        "\n",
        "  implG = persistence_routine(filtered_v_G, filtered_e_G, edge_index_G)[0]\n",
        "  implH = persistence_routine(filtered_v_H, filtered_e_H, edge_index_H)[0]\n",
        "\n",
        "  return (implG, implH), ((input_v_G, edge_index_G, filtered_v_G, filtered_e_G), (input_v_H, edge_index_H, filtered_v_H, filtered_e_H))\n",
        "\n",
        "impl_list = []\n",
        "graph_data_list = []\n",
        "\n",
        "for item in dataset:\n",
        "  entry_impl, entry_gd = dataset_entry_to_input(item)\n",
        "  impl_list.append(entry_impl)\n",
        "  graph_data_list.append(entry_gd)\n"
      ],
      "metadata": {
        "id": "jLL9cFxflm_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the results for the 3 implementations\n",
        "\n",
        "# Theorem 4\n",
        "thm_4_pd_list = []\n",
        "for ind in range(0, len(graph_data_list)):\n",
        "  # Theorem 4 Implementation\n",
        "  output = thm4_ph(graph_data_list[ind])\n",
        "  thm_4_pd_list.append(output)\n",
        "\n",
        "# Compute the actual NetworkX graph of the product of the two graphs\n",
        "P_list = []\n",
        "for item in dataset:\n",
        "  G, H = item\n",
        "  P = nx.cartesian_product(G, H)\n",
        "  P_list.append(P)\n",
        "\n",
        "# Naive Union-Find\n",
        "naive_pd_list = []\n",
        "for ind in range(0, len(graph_data_list)):\n",
        "  output = naive_pd(graph_data_list[ind], P_list[ind])\n",
        "  naive_pd_list.append(output)\n",
        "\n",
        "# gudhi\n",
        "gudhi_pd_list = []\n",
        "for ind in range(0, len(graph_data_list)):\n",
        "  output = gudhi_prod(graph_data_list[ind], P_list[ind])\n",
        "  gudhi_pd_list.append(output)"
      ],
      "metadata": {
        "id": "yapsEdVHlYvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions to check if two persistence diagrams are equal\n",
        "def pd_to_multiset(pd_list):\n",
        "  output = {}\n",
        "  for item in pd_list:\n",
        "    output[str(item)] = 0\n",
        "  for item in pd_list:\n",
        "    output[str(item)] += 1\n",
        "  return output\n",
        "\n",
        "def check_pd_equal(pd1, pd2):\n",
        "  pd1_list = pd_to_multiset(pd1)\n",
        "  pd2_list = pd_to_multiset(pd2)\n",
        "\n",
        "  return pd1_list, pd2_list, pd1_list == pd2_list"
      ],
      "metadata": {
        "id": "0AXQuKW9kEsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dP9oG3UKaF_",
        "outputId": "fbbe4eb3-c568-4b76-a42a-04da804b4859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Checking that the outputs match each other\n",
        "for i in range(0, len(naive_pd_list)):\n",
        "  thm4_output = thm_4_pd_list[i]\n",
        "  naive_output = naive_pd_list[i]\n",
        "  gudhi_output = gudhi_pd_list[i]\n",
        "\n",
        "  # _, _, value = check_pd_equal(thm4_output, gudhi_output)\n",
        "  # print(value)\n",
        "  left_list, middle_list, value = check_pd_equal(thm4_output, naive_output)\n",
        "  middle_list, right_list, value1 = check_pd_equal(naive_output, gudhi_output)\n",
        "\n",
        "  if value and value1:\n",
        "    print(True)\n",
        "  else:\n",
        "    print(\"False: \", i)\n",
        "    print(\"Thm4 = Naive\", value)\n",
        "    print(\"Naive = gudhi\", value1)\n",
        "    print(left_list)\n",
        "    print(middle_list)\n",
        "    print(right_list)\n",
        "    print(\"--------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}